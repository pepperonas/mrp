import type { ApiResponse } from './openai';

export const optimizeGemini = async (
  prompt: string,
  apiKey: string,
  model: string,
  maxTokens: number,
  temperature: number
): Promise<ApiResponse> => {
  // Gemini API verwendet einen anderen Endpoint-Format
  const modelName = model.includes('gemini') ? model : `models/${model}`;
  const url = `https://generativelanguage.googleapis.com/v1beta/${modelName}:generateContent?key=${apiKey}`;

  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      contents: [
        {
          parts: [
            {
              text: prompt,
            },
          ],
        },
      ],
      generationConfig: {
        maxOutputTokens: maxTokens,
        temperature,
      },
    }),
  });

  if (!response.ok) {
    const error = await response.json().catch(() => ({ error: { message: 'Unknown error' } })) as {
      error?: { message?: string };
    };
    throw new Error(error.error?.message || `HTTP ${response.status}`);
  }

  const data = await response.json() as {
    candidates?: Array<{ content?: { parts?: Array<{ text?: string }> } }>;
    usageMetadata?: { promptTokenCount?: number; candidatesTokenCount?: number };
  };
  const content = data.candidates?.[0]?.content?.parts?.[0]?.text?.trim() || '';
  const usage = data.usageMetadata;
  
  return {
    content,
    tokenUsage: usage ? {
      inputTokens: usage.promptTokenCount || 0,
      outputTokens: usage.candidatesTokenCount || 0,
    } : undefined,
  };
};

